{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d3aa70c",
   "metadata": {},
   "source": [
    "## Fit a \"Regional Grain Size Model\" to NI and Mass and E  Australia samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832429a8",
   "metadata": {},
   "source": [
    "Daniel Buscombe, Sept 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90adaf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbuscombe\\Anaconda3\\envs\\cgrasp\\lib\\site-packages\\outdated\\utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.5.1, the latest is 0.5.2.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from pingouin import partial_corr\n",
    "import pingouin as pg\n",
    "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import geopandas as gpd\n",
    "from geopandas.tools import sjoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51fbd11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do_gs_strat = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "066279bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNI = pd.read_csv('../model_data/dataset_NI_strat_gs.csv')\n",
    "dfMass = pd.read_csv('../model_data/dataset_Mass_strat_gs.csv')\n",
    "dfMass = dfMass[dfMass['d50']<=2.0]\n",
    "\n",
    "dfMass['code'] = np.ones(len(dfMass))\n",
    "dfNI['code'] = np.zeros(len(dfNI))\n",
    "\n",
    "dfNI = dfNI[['latitude', 'longitude', 'd50', 'beach_slope_average', 'mstr','code',\n",
    "       'hs_mean']]\n",
    "\n",
    "dfMass = dfMass[['latitude', 'longitude', 'd50', 'beach_slope_average', 'mstr', 'code',\n",
    "       'hs_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa8898d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b927ab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfMass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1bd3adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEAus = pd.read_csv('../model_data/dataset_E_Aus_coast_strat_gs.csv')\n",
    "dfEAus['code'] = np.ones(len(dfEAus))*2\n",
    "dfEAus = dfEAus[['latitude', 'longitude', 'd50', 'beach_slope_average', 'mstr', 'code',\n",
    "       'hs_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7f85bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>d50</th>\n",
       "      <th>beach_slope_average</th>\n",
       "      <th>mstr</th>\n",
       "      <th>code</th>\n",
       "      <th>hs_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-30.366631</td>\n",
       "      <td>153.104779</td>\n",
       "      <td>0.22170</td>\n",
       "      <td>0.051248</td>\n",
       "      <td>1.876848</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.768335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-36.075447</td>\n",
       "      <td>150.133855</td>\n",
       "      <td>0.25120</td>\n",
       "      <td>0.048650</td>\n",
       "      <td>1.641057</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.208976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-29.489168</td>\n",
       "      <td>153.361658</td>\n",
       "      <td>0.20880</td>\n",
       "      <td>0.055725</td>\n",
       "      <td>1.929132</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.588566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-30.366631</td>\n",
       "      <td>153.104779</td>\n",
       "      <td>0.22170</td>\n",
       "      <td>0.051248</td>\n",
       "      <td>1.876848</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.768335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-30.021327</td>\n",
       "      <td>153.209451</td>\n",
       "      <td>0.14580</td>\n",
       "      <td>0.064156</td>\n",
       "      <td>1.893739</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.635126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>-26.597765</td>\n",
       "      <td>153.100290</td>\n",
       "      <td>0.95264</td>\n",
       "      <td>0.060769</td>\n",
       "      <td>2.036081</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.498618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>-26.597765</td>\n",
       "      <td>153.100290</td>\n",
       "      <td>0.95264</td>\n",
       "      <td>0.060769</td>\n",
       "      <td>2.036081</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.498618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>-26.597765</td>\n",
       "      <td>153.100290</td>\n",
       "      <td>0.95264</td>\n",
       "      <td>0.060769</td>\n",
       "      <td>2.036081</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.498618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>-26.597765</td>\n",
       "      <td>153.100290</td>\n",
       "      <td>0.95264</td>\n",
       "      <td>0.060769</td>\n",
       "      <td>2.036081</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.498618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>-26.597765</td>\n",
       "      <td>153.100290</td>\n",
       "      <td>0.95264</td>\n",
       "      <td>0.060769</td>\n",
       "      <td>2.036081</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.498618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      latitude   longitude      d50  beach_slope_average      mstr  code  \\\n",
       "0   -30.366631  153.104779  0.22170             0.051248  1.876848   2.0   \n",
       "1   -36.075447  150.133855  0.25120             0.048650  1.641057   2.0   \n",
       "2   -29.489168  153.361658  0.20880             0.055725  1.929132   2.0   \n",
       "3   -30.366631  153.104779  0.22170             0.051248  1.876848   2.0   \n",
       "4   -30.021327  153.209451  0.14580             0.064156  1.893739   2.0   \n",
       "..         ...         ...      ...                  ...       ...   ...   \n",
       "235 -26.597765  153.100290  0.95264             0.060769  2.036081   2.0   \n",
       "236 -26.597765  153.100290  0.95264             0.060769  2.036081   2.0   \n",
       "237 -26.597765  153.100290  0.95264             0.060769  2.036081   2.0   \n",
       "238 -26.597765  153.100290  0.95264             0.060769  2.036081   2.0   \n",
       "239 -26.597765  153.100290  0.95264             0.060769  2.036081   2.0   \n",
       "\n",
       "      hs_mean  \n",
       "0    1.768335  \n",
       "1    1.208976  \n",
       "2    1.588566  \n",
       "3    1.768335  \n",
       "4    1.635126  \n",
       "..        ...  \n",
       "235  1.498618  \n",
       "236  1.498618  \n",
       "237  1.498618  \n",
       "238  1.498618  \n",
       "239  1.498618  \n",
       "\n",
       "[240 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfEAus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cf9fa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([dfNI, dfMass, dfEAus], ignore_index=True)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b76d746b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand = np.random.randn(len(df))\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "608eef69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>d50</th>\n",
       "      <th>beach_slope_average</th>\n",
       "      <th>mstr</th>\n",
       "      <th>code</th>\n",
       "      <th>hs_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55.230840</td>\n",
       "      <td>-6.519184</td>\n",
       "      <td>0.28000</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.065955</td>\n",
       "      <td>-6.060966</td>\n",
       "      <td>0.16900</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.841990</td>\n",
       "      <td>-8.443956</td>\n",
       "      <td>0.18000</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55.202304</td>\n",
       "      <td>-6.655600</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.164820</td>\n",
       "      <td>-6.788414</td>\n",
       "      <td>0.16600</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-26.597765</td>\n",
       "      <td>153.100290</td>\n",
       "      <td>0.95264</td>\n",
       "      <td>0.060769</td>\n",
       "      <td>2.036081</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.498618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>-26.597765</td>\n",
       "      <td>153.100290</td>\n",
       "      <td>0.95264</td>\n",
       "      <td>0.060769</td>\n",
       "      <td>2.036081</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.498618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>-26.597765</td>\n",
       "      <td>153.100290</td>\n",
       "      <td>0.95264</td>\n",
       "      <td>0.060769</td>\n",
       "      <td>2.036081</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.498618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>-26.597765</td>\n",
       "      <td>153.100290</td>\n",
       "      <td>0.95264</td>\n",
       "      <td>0.060769</td>\n",
       "      <td>2.036081</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.498618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>-26.597765</td>\n",
       "      <td>153.100290</td>\n",
       "      <td>0.95264</td>\n",
       "      <td>0.060769</td>\n",
       "      <td>2.036081</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.498618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>415 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      latitude   longitude      d50  beach_slope_average      mstr  code  \\\n",
       "0    55.230840   -6.519184  0.28000             0.032900  1.500000   0.0   \n",
       "1    55.065955   -6.060966  0.16900             0.034000  1.400000   0.0   \n",
       "2    54.841990   -8.443956  0.18000             0.021800  3.400000   0.0   \n",
       "3    55.202304   -6.655600  0.18600             0.032000  1.500000   0.0   \n",
       "4    55.164820   -6.788414  0.16600             0.021400  1.500000   0.0   \n",
       "..         ...         ...      ...                  ...       ...   ...   \n",
       "410 -26.597765  153.100290  0.95264             0.060769  2.036081   2.0   \n",
       "411 -26.597765  153.100290  0.95264             0.060769  2.036081   2.0   \n",
       "412 -26.597765  153.100290  0.95264             0.060769  2.036081   2.0   \n",
       "413 -26.597765  153.100290  0.95264             0.060769  2.036081   2.0   \n",
       "414 -26.597765  153.100290  0.95264             0.060769  2.036081   2.0   \n",
       "\n",
       "      hs_mean  \n",
       "0    2.180000  \n",
       "1    1.360000  \n",
       "2    2.180000  \n",
       "3    2.340000  \n",
       "4    2.260000  \n",
       "..        ...  \n",
       "410  1.498618  \n",
       "411  1.498618  \n",
       "412  1.498618  \n",
       "413  1.498618  \n",
       "414  1.498618  \n",
       "\n",
       "[415 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ca0a01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['code']==1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdc9f58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['code']==0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d64dc862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['code']==2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e66a1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'n_estimators':[25,50, 100,200,300, 500], \n",
    "    'max_depth':[3,5,7,9,11], \n",
    "    \"min_samples_split\":[3,5,7,9,11], \n",
    "    \"learning_rate\": [0.01,0.05, 0.075, 0.1], \n",
    "    \"subsample\": [0.25,0.5,0.75,1.0],\n",
    "    \"loss\": [\"squared_error\", \"absolute_error\", \"huber\"]\n",
    "}\n",
    "\n",
    "##27 individual parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138db279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b79df937",
   "metadata": {},
   "outputs": [],
   "source": [
    "Smean = []\n",
    "Sstd = []\n",
    "\n",
    "test_size = 0.6\n",
    "\n",
    "standardize = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfeddbc",
   "metadata": {},
   "source": [
    "### model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c55fa7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.370240964\n",
      "1.370240964\n",
      "Fitting 5 folds for each of 7200 candidates, totalling 36000 fits\n"
     ]
    }
   ],
   "source": [
    "feature_names1 = ['β (radians)', 'Random\\n (non-dim.)']\n",
    "X = np.stack((df['beach_slope_average'], rand))\n",
    "X.shape\n",
    "\n",
    "if standardize:\n",
    "    xscaler = preprocessing.StandardScaler().fit(X)\n",
    "    X = xscaler.transform(X)\n",
    "    print('Covariates standardized')\n",
    "    \n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(\n",
    "    X.T, df['d50'], test_size=test_size, random_state=2022\n",
    ")\n",
    "\n",
    "print(y_test1.max())\n",
    "print(y_train1.max())\n",
    "\n",
    "# model1 = ensemble.GradientBoostingRegressor(**params)\n",
    "gbr = ensemble.GradientBoostingRegressor()#**params)\n",
    "\n",
    "model1 = GridSearchCV(gbr, parameters, n_jobs=-1, verbose=2)\n",
    "model1.fit(X_train1, y_train1)\n",
    "\n",
    "mse1 = mean_squared_error(y_test1, model1.predict(X_test1))\n",
    "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse1))\n",
    "\n",
    "print(model1.best_params_)\n",
    "\n",
    "model1out = {}\n",
    "model1out['feature_names'] = feature_names1\n",
    "model1out['Xtest'] = X_test1\n",
    "model1out['Xtrain'] = X_train1\n",
    "model1out['ytest'] = y_test1\n",
    "model1out['ytrain'] = y_train1\n",
    "model1out['model'] = model1\n",
    "model1out['mse'] = mse1\n",
    "model1out['best_params'] = model1.best_params_\n",
    "\n",
    "model1 = model1.best_estimator_\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=5, random_state=2022)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model1, X_test1, y_test1, scoring='neg_root_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "# force scores to be positive\n",
    "scores = np.absolute(scores)\n",
    "print('Mean RMSE: %.3f (%.3f)' % (scores.mean(), scores.std()) )\n",
    "\n",
    "Smean.append(scores.mean())\n",
    "Sstd.append(scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061a224a",
   "metadata": {},
   "source": [
    "### model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b50c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names2 = [r'MSTR (m)', 'Random\\n (non-dim.)']\n",
    "X = np.stack((df['mstr'], rand))\n",
    "X.shape\n",
    "\n",
    "if standardize:\n",
    "    xscaler = preprocessing.StandardScaler().fit(X)\n",
    "    X = xscaler.transform(X)\n",
    "    print('Covariates standardized')\n",
    "    \n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
    "    X.T, df['d50'], test_size=test_size, random_state=2022\n",
    ")\n",
    "\n",
    "print(y_test2.max())\n",
    "print(y_train2.max())\n",
    "\n",
    "# model2 = ensemble.GradientBoostingRegressor(**params)\n",
    "gbr = ensemble.GradientBoostingRegressor()#**params)\n",
    "\n",
    "model2 = GridSearchCV(gbr, parameters, n_jobs=-1, verbose=2)\n",
    "model2.fit(X_train2, y_train2)\n",
    "\n",
    "mse2 = mean_squared_error(y_test2, model2.predict(X_test2))\n",
    "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse2))\n",
    "\n",
    "print(model2.best_params_)\n",
    "model2out = {}\n",
    "model2out['feature_names'] = feature_names2\n",
    "model2out['Xtest'] = X_test2\n",
    "model2out['Xtrain'] = X_train2\n",
    "model2out['ytest'] = y_test2\n",
    "model2out['ytrain'] = y_train2\n",
    "model2out['model'] = model2\n",
    "model2out['mse'] = mse2\n",
    "model2out['best_params'] = model2.best_params_\n",
    "\n",
    "model2 = model2.best_estimator_\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=5, random_state=2022)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model2, X_test2, y_test2, scoring='neg_root_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "# force scores to be positive\n",
    "scores = np.absolute(scores)\n",
    "print('Mean RMSE: %.3f (%.3f)' % (scores.mean(), scores.std()) )\n",
    "\n",
    "Smean.append(scores.mean())\n",
    "Sstd.append(scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03677685",
   "metadata": {},
   "source": [
    "### model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e79b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names3 = ['β (radians)','MSTR (m)', 'Random\\n (non-dim.)']\n",
    "X = np.stack((df['beach_slope_average'], df['mstr'], rand))\n",
    "X.shape\n",
    "\n",
    "if standardize:\n",
    "    xscaler = preprocessing.StandardScaler().fit(X)\n",
    "    X = xscaler.transform(X)\n",
    "    print('Covariates standardized')\n",
    "\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(\n",
    "    X.T, df['d50'], test_size=test_size, random_state=2022\n",
    ")\n",
    "\n",
    "print(y_test3.max())\n",
    "print(y_train3.max())\n",
    "\n",
    "# model3 = ensemble.GradientBoostingRegressor(**params)\n",
    "gbr = ensemble.GradientBoostingRegressor()#**params)\n",
    "\n",
    "model3 = GridSearchCV(gbr, parameters, n_jobs=-1, verbose=2)\n",
    "model3.fit(X_train3, y_train3)\n",
    "\n",
    "mse3 = mean_squared_error(y_test3, model3.predict(X_test3))\n",
    "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse3))\n",
    "\n",
    "print(model3.best_params_)\n",
    "model3out = {}\n",
    "model3out['feature_names'] = feature_names3\n",
    "model3out['Xtest'] = X_test3\n",
    "model3out['Xtrain'] = X_train3\n",
    "model3out['ytest'] = y_test3\n",
    "model3out['ytrain'] = y_train3\n",
    "model3out['model'] = model3\n",
    "model3out['mse'] = mse3\n",
    "model3out['best_params'] = model3.best_params_\n",
    "\n",
    "model3 = model3.best_estimator_\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=5, random_state=2022)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model3, X_test3, y_test3, scoring='neg_root_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "# force scores to be positive\n",
    "scores = np.absolute(scores)\n",
    "print('Mean RMSE: %.3f (%.3f)' % (scores.mean(), scores.std()) )\n",
    "\n",
    "Smean.append(scores.mean())\n",
    "Sstd.append(scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23bb976",
   "metadata": {},
   "source": [
    "### model 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8446330a",
   "metadata": {},
   "source": [
    "### model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0caac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names5 = ['β (radians)','MSTR (m)',r'$H_s$ (m)', 'Random\\n (non-dim.)']\n",
    "X = np.stack((df['beach_slope_average'], df['mstr'], df['hs_mean'], rand))\n",
    "X.shape\n",
    "\n",
    "if standardize:\n",
    "    xscaler = preprocessing.StandardScaler().fit(X)\n",
    "    X = xscaler.transform(X)\n",
    "    print('Covariates standardized')\n",
    "\n",
    "X_train5, X_test5, y_train5, y_test5 = train_test_split(\n",
    "    X.T, df['d50'], test_size=test_size, random_state=2022\n",
    ")\n",
    "\n",
    "print(y_test5.max())\n",
    "print(y_train5.max())\n",
    "\n",
    "# model5 = ensemble.GradientBoostingRegressor(**params)\n",
    "gbr = ensemble.GradientBoostingRegressor()#**params)\n",
    "\n",
    "model5 = GridSearchCV(gbr, parameters, n_jobs=-1, verbose=2)\n",
    "model5.fit(X_train5, y_train5)\n",
    "\n",
    "mse5 = mean_squared_error(y_test5, model5.predict(X_test5))\n",
    "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse5))\n",
    "\n",
    "print(model5.best_params_)\n",
    "model5out = {}\n",
    "model5out['feature_names'] = feature_names5\n",
    "model5out['Xtest'] = X_test5\n",
    "model5out['Xtrain'] = X_train5\n",
    "model5out['ytest'] = y_test5\n",
    "model5out['ytrain'] = y_train5\n",
    "model5out['model'] = model5\n",
    "model5out['mse'] = mse5\n",
    "model5out['best_params'] = model5.best_params_\n",
    "\n",
    "model5 = model5.best_estimator_\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=5, random_state=2022)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model5, X_test5, y_test5, scoring='neg_root_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "# force scores to be positive\n",
    "scores = np.absolute(scores)\n",
    "print('Mean RMSE: %.3f (%.3f)' % (scores.mean(), scores.std()) )\n",
    "\n",
    "Smean.append(scores.mean())\n",
    "Sstd.append(scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4d2f88",
   "metadata": {},
   "source": [
    "### model 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cdb9c9",
   "metadata": {},
   "source": [
    "### model 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be59cdf",
   "metadata": {},
   "source": [
    "### model 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd54285",
   "metadata": {},
   "source": [
    "### plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5052a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prc_err(y,yest):\n",
    "    return 100*(np.abs(y-yest)/y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c75620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "plt.subplot(221)\n",
    "ds_est = model1.predict(X_test1)\n",
    "plt.plot(y_test1, ds_est, 'ko', label='Test data')\n",
    "plt.xlim(0.063,1.6); plt.ylim(0.063,1.6)\n",
    "\n",
    "yl=plt.ylim()\n",
    "plt.plot(yl,yl,'--r')\n",
    "plt.xlabel(r'Observed $D_{50}$ (mm)')\n",
    "plt.ylabel(r'Estimated $D_{50}$ (mm)')\n",
    "plt.title(r\"a) f(β)\", loc='left')\n",
    "r2 = np.min(np.corrcoef(y_test1, ds_est))**2\n",
    "plt.text(1.2,.5,r'$R^2$ (test)='+str(r2)[:4])\n",
    "\n",
    "coef = np.polyfit(y_test1, ds_est,1)\n",
    "poly1d_fn = np.poly1d(coef) \n",
    "plt.plot(y_test1, poly1d_fn(y_test1), '-k')\n",
    "plt.text(1.2,.4, r'Mean error: {}%'.format(str(np.mean(prc_err(y_test1,ds_est)))[:2]))\n",
    "\n",
    "ds_est2 = model1.predict(X_train1)\n",
    "plt.plot(y_train1, ds_est2, 'bp', alpha=0.5, label='Train data')\n",
    "plt.legend(loc=0)\n",
    "\n",
    "plt.text(1.2,.2, r'Overall mean error:', color='g')\n",
    "plt.text(1.2,.1, r'{}%'.format(str(np.mean(prc_err(np.hstack((y_test1,y_train1)),np.hstack((ds_est,ds_est2)))))[:2]), color='g')\n",
    "\n",
    "plt.subplot(222)\n",
    "ds_est = model2.predict(X_test2)\n",
    "plt.plot(y_test2, ds_est, 'ko')\n",
    "plt.xlim(0.063,1.6); plt.ylim(0.063,1.6)\n",
    "\n",
    "yl=plt.ylim()\n",
    "plt.plot(yl,yl,'--r')\n",
    "plt.xlabel(r'Observed $D_{50}$ (mm)')\n",
    "plt.title(r\"b) f($MSTR$)\", loc='left')\n",
    "r2 = np.min(np.corrcoef(y_test2, ds_est))**2\n",
    "plt.text(1.2,.5,r'$R^2$='+str(r2)[:4])\n",
    "\n",
    "coef = np.polyfit(y_test2, ds_est,1)\n",
    "poly1d_fn = np.poly1d(coef) \n",
    "plt.plot(y_test2, poly1d_fn(y_test2), '-k')\n",
    "plt.text(1.2,.4, r'Mean error: {}%'.format(str(np.mean(prc_err(y_test2,ds_est)))[:2]))\n",
    "\n",
    "ds_est2 = model2.predict(X_train2)\n",
    "plt.plot(y_train2, ds_est2, 'bp', alpha=0.5, label='Train data')\n",
    "\n",
    "plt.text(1.2,.2, r'Overall mean error:', color='g')\n",
    "plt.text(1.2,.1, r'{}%'.format(str(np.mean(prc_err(np.hstack((y_test2,y_train2)),np.hstack((ds_est,ds_est2)))))[:2]), color='g')\n",
    "\n",
    "plt.subplot(223)\n",
    "ds_est = model3.predict(X_test3)\n",
    "plt.plot(y_test3, ds_est, 'ko')\n",
    "plt.xlim(0.063,1.6); plt.ylim(0.063,1.6)\n",
    "\n",
    "yl=plt.ylim()\n",
    "plt.plot(yl,yl,'--r')\n",
    "plt.xlabel(r'Observed $D_{50}$ (mm)')\n",
    "plt.title(\"c) f(β, $MSTR$)\", loc='left')\n",
    "r2 = np.min(np.corrcoef(y_test3, ds_est))**2\n",
    "plt.text(1.2,.5,r'$R^2$ (test)='+str(r2)[:4])\n",
    "\n",
    "coef = np.polyfit(y_test3, ds_est,1)\n",
    "poly1d_fn = np.poly1d(coef) \n",
    "plt.plot(y_test3, poly1d_fn(y_test3), '-k')\n",
    "plt.text(1.2,.4, r'Mean error: {}%'.format(str(np.mean(prc_err(y_test3,ds_est)))[:2]))\n",
    "\n",
    "ds_est2 = model3.predict(X_train3)\n",
    "plt.plot(y_train3, ds_est2, 'bp', alpha=0.5, label='Train data')\n",
    "\n",
    "plt.text(1.2,.2, r'Overall mean error:', color='g')\n",
    "plt.text(1.2,.1, r'{}%'.format(str(np.mean(prc_err(np.hstack((y_test3,y_train3)),np.hstack((ds_est,ds_est2)))))[:2]), color='g')\n",
    "\n",
    "plt.subplot(224)\n",
    "ds_est = model5.predict(X_test5)\n",
    "plt.plot(y_test5, ds_est, 'ko')\n",
    "plt.xlim(0.063,1.6); plt.ylim(0.063,1.6)\n",
    "\n",
    "yl=plt.ylim()\n",
    "plt.plot(yl,yl,'--r')\n",
    "plt.xlabel(r'Observed $D_{50}$ (mm)')\n",
    "plt.ylabel(r'Estimated $D_{50}$ (mm)')\n",
    "plt.title(r\"d) f(β, $MSTR$, $H_s$)\", loc='left')\n",
    "r2 = np.min(np.corrcoef(y_test5, ds_est))**2\n",
    "plt.text(1.2,.5,r'$R^2$ (test)='+str(r2)[:4])\n",
    "\n",
    "coef = np.polyfit(y_test5, ds_est,1)\n",
    "poly1d_fn = np.poly1d(coef) \n",
    "plt.plot(y_test5, poly1d_fn(y_test5), '-k')\n",
    "plt.text(1.2,.4, r'Mean error: {}%'.format(str(np.mean(prc_err(y_test5,ds_est)))[:2]))\n",
    "\n",
    "ds_est2 = model5.predict(X_train5)\n",
    "plt.plot(y_train5, ds_est2, 'bp', alpha=0.5, label='Train data')\n",
    "\n",
    "plt.text(1.2,.2, r'Overall mean error:', color='g')\n",
    "plt.text(1.2,.1, r'{}%'.format(str(np.mean(prc_err(np.hstack((y_test5,y_train5)),np.hstack((ds_est,ds_est2)))))[:2]), color='g')\n",
    "\n",
    "\n",
    "# plt.savefig('../model_plots/ThreeRegions_NI_Mass_EAus_d50-4models-skill-FINAL.jpg', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('../model_plots/ThreeRegions_NI_Mass_EAus_d50-4models-skill-FINAL2.jpg', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9972d589",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "C = np.stack((df['code']))\n",
    "C_train1, C_test1, _, _ = train_test_split(\n",
    "    C.T, df['d50'], test_size=test_size, random_state=2022\n",
    ")\n",
    "\n",
    "plt.subplot(221)\n",
    "ds_est = model1.predict(X_test1)\n",
    "plt.plot(y_test1[C_test1==0], ds_est[C_test1==0], 'bp', label='N. Ire.')\n",
    "plt.plot(y_test1[C_test1==1], ds_est[C_test1==1], 'rs', label='Mass.')\n",
    "plt.plot(y_test1[C_test1==2], ds_est[C_test1==2], 'm.', label='E. Aus.')\n",
    "\n",
    "\n",
    "plt.xlim(0.063,1.6); plt.ylim(0.063,1.6)\n",
    "yl=plt.ylim()\n",
    "plt.plot(yl,yl,'--r')\n",
    "plt.xlabel(r'Observed $D_{50}$ (mm)')\n",
    "plt.ylabel(r'Estimated $D_{50}$ (mm)')\n",
    "plt.title(r\"a) f(β)\", loc='left')\n",
    "r2 = np.min(np.corrcoef(y_test1, ds_est))**2\n",
    "plt.text(1.2,.6,r'$R^2$ (test)='+str(r2)[:4])\n",
    "\n",
    "coef = np.polyfit(y_test1, ds_est,1)\n",
    "poly1d_fn = np.poly1d(coef) \n",
    "plt.plot(y_test1, poly1d_fn(y_test1), '-k')\n",
    "plt.text(1.2,.5, r'Mean error: {}%'.format(str(np.mean(prc_err(y_test1,ds_est)))[:2]))\n",
    "\n",
    "plt.text(1.2,.3, r'Mean error: {}%'.format(str(np.mean(prc_err(y_test1[C_test1==0],ds_est[C_test1==0])))[:2]), color='b')\n",
    "plt.text(1.2,.2, r'Mean error: {}%'.format(str(np.mean(prc_err(y_test1[C_test1==1],ds_est[C_test1==1])))[:2]), color='r')\n",
    "plt.text(1.2,.1, r'Mean error: {}%'.format(str(np.mean(prc_err(y_test1[C_test1==2],ds_est[C_test1==2])))[:2]), color='m')\n",
    "\n",
    "plt.legend(loc=1)\n",
    "\n",
    "plt.subplot(222)\n",
    "ds_est = model2.predict(X_test2)\n",
    "plt.plot(y_test2[C_test1==0], ds_est[C_test1==0], 'bp', label='E. Aus.')\n",
    "plt.plot(y_test2[C_test1==1], ds_est[C_test1==1], 'rs', label='S.E. U.S')\n",
    "plt.plot(y_test2[C_test1==2], ds_est[C_test1==2], 'm.', label='E. Aus.')\n",
    "\n",
    "plt.xlim(0.063,1.6); plt.ylim(0.063,1.6)\n",
    "yl=plt.ylim()\n",
    "plt.plot(yl,yl,'--r')\n",
    "plt.xlabel(r'Observed $D_{50}$ (mm)')\n",
    "plt.title(r\"b) f($MSTR$)\", loc='left')\n",
    "r2 = np.min(np.corrcoef(y_test2, ds_est))**2\n",
    "plt.text(1.2,.6,r'$R^2$='+str(r2)[:4])\n",
    "\n",
    "coef = np.polyfit(y_test2, ds_est,1)\n",
    "poly1d_fn = np.poly1d(coef) \n",
    "plt.plot(y_test2, poly1d_fn(y_test2), '-k')\n",
    "plt.text(1.2,.5, r'Mean error: {}%'.format(str(np.mean(prc_err(y_test2,ds_est)))[:2]))\n",
    "# plt.text(1.2,.4, r'MSE: {}mm'.format(str(Smean[1])[:4]))\n",
    "\n",
    "ds_est2 = model2.predict(X_train2)\n",
    "plt.plot(y_train2, ds_est2, 'bp', alpha=0.5, label='Train data')\n",
    "\n",
    "plt.text(1.2,.3, r'Mean error: {}%'.format(str(np.mean(prc_err(y_test2[C_test1==0],ds_est[C_test1==0])))[:2]), color='b')\n",
    "plt.text(1.2,.2, r'Mean error: {}%'.format(str(np.mean(prc_err(y_test2[C_test1==1],ds_est[C_test1==1])))[:2]), color='r')\n",
    "plt.text(1.2,.1, r'Mean error: {}%'.format(str(np.mean(prc_err(y_test2[C_test1==2],ds_est[C_test1==2])))[:2]), color='m')\n",
    "\n",
    "\n",
    "plt.subplot(223)\n",
    "ds_est = model3.predict(X_test3)\n",
    "plt.plot(y_test3[C_test1==0], ds_est[C_test1==0], 'bp', label='E. Aus.')\n",
    "plt.plot(y_test3[C_test1==1], ds_est[C_test1==1], 'rs', label='S.E. U.S')\n",
    "plt.plot(y_test3[C_test1==2], ds_est[C_test1==2], 'm.', label='E. Aus.')\n",
    "\n",
    "plt.xlim(0.063,1.6); plt.ylim(0.063,1.6)\n",
    "yl=plt.ylim()\n",
    "plt.plot(yl,yl,'--r')\n",
    "plt.xlabel(r'Observed $D_{50}$ (mm)')\n",
    "plt.title(\"c) f(β, $MSTR$)\", loc='left')\n",
    "r2 = np.min(np.corrcoef(y_test3, ds_est))**2\n",
    "plt.text(1.2,.6,r'$R^2$ (test)='+str(r2)[:4])\n",
    "\n",
    "coef = np.polyfit(y_test3, ds_est,1)\n",
    "poly1d_fn = np.poly1d(coef) \n",
    "plt.plot(y_test3, poly1d_fn(y_test3), '-k')\n",
    "plt.text(1.2,.5, r'Mean error: {}%'.format(str(np.mean(prc_err(y_test3,ds_est)))[:2]))\n",
    "\n",
    "ds_est2 = model3.predict(X_train3)\n",
    "plt.plot(y_train3, ds_est2, 'bp', alpha=0.5, label='Train data')\n",
    "\n",
    "plt.text(1.2,.3, r'Mean error: {}%'.format(str(np.mean(prc_err(y_test3[C_test1==0],ds_est[C_test1==0])))[:2]), color='b')\n",
    "plt.text(1.2,.2, r'Mean error: {}%'.format(str(np.mean(prc_err(y_test3[C_test1==1],ds_est[C_test1==1])))[:2]), color='r')\n",
    "plt.text(1.2,.1, r'Mean error: {}%'.format(str(np.mean(prc_err(y_test3[C_test1==2],ds_est[C_test1==2])))[:2]), color='m')\n",
    "\n",
    "\n",
    "plt.subplot(224)\n",
    "ds_est = model5.predict(X_test5)\n",
    "plt.plot(y_test5[C_test1==0], ds_est[C_test1==0], 'bp', label='E. Aus.')\n",
    "plt.plot(y_test5[C_test1==1], ds_est[C_test1==1], 'rs', label='S.E. U.S')\n",
    "plt.plot(y_test5[C_test1==2], ds_est[C_test1==2], 'm.', label='E. Aus.')\n",
    "\n",
    "plt.xlim(0.063,1.6); plt.ylim(0.063,1.6)\n",
    "yl=plt.ylim()\n",
    "plt.plot(yl,yl,'--r')\n",
    "plt.xlabel(r'Observed $D_{50}$ (mm)')\n",
    "plt.ylabel(r'Estimated $D_{50}$ (mm)')\n",
    "plt.title(r\"d) f(β, $MSTR$, $H_s$)\", loc='left')\n",
    "r2 = np.min(np.corrcoef(y_test5, ds_est))**2\n",
    "plt.text(1.2,.6,r'$R^2$ (test)='+str(r2)[:4])\n",
    "\n",
    "coef = np.polyfit(y_test5, ds_est,1)\n",
    "poly1d_fn = np.poly1d(coef) \n",
    "plt.plot(y_test5, poly1d_fn(y_test5), '-k')\n",
    "plt.text(1.2,.5, r'Mean error: {}%'.format(str(np.mean(prc_err(y_test5,ds_est)))[:2]))\n",
    "\n",
    "ds_est2 = model5.predict(X_train5)\n",
    "plt.plot(y_train5, ds_est2, 'bp', alpha=0.5, label='Train data')\n",
    "\n",
    "plt.text(1.2,.3, r'Mean error: {}%'.format(str(np.mean(prc_err(y_test5[C_test1==0],ds_est[C_test1==0])))[:2]), color='b')\n",
    "plt.text(1.2,.2, r'Mean error: {}%'.format(str(np.mean(prc_err(y_test5[C_test1==1],ds_est[C_test1==1])))[:2]), color='r')\n",
    "plt.text(1.2,.1, r'Mean error: {}%'.format(str(np.mean(prc_err(y_test5[C_test1==2],ds_est[C_test1==2])))[:2]), color='m')\n",
    "\n",
    "\n",
    "# plt.savefig('../model_plots/ThreeRegions_NI_Mass_EAus_d50-4models-skill-by-dataset-FINAL.jpg', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('../model_plots/ThreeRegions_NI_Mass_EAus_d50-4models-skill-by-dataset-FINAL2.jpg', dpi=300, bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49edcae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf00fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccf9310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.stack((df['beach_slope_average'], df['mstr'], df['tp'], df['hs_mean'],  rand))\n",
    "# ds_est8 = model8.predict(X.T)\n",
    "\n",
    "# X = np.stack((df['beach_slope_average'], df['mstr'], df['tp'], rand))\n",
    "# ds_est4 = model4.predict(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a475cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "# plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "# plt.subplot(221)\n",
    "# plt.stem(df['d50'], df['d50']-ds_est8,  markerfmt='o', linefmt='-', label=r\"f(β, $MSTR$, $T_p$, $H_s$)\")\n",
    "# plt.stem(df['d50'], df['d50']-ds_est4,  markerfmt='p', linefmt='-', label = r\"f(β, $MSTR$, $T_p$)\" )\n",
    "# plt.legend()\n",
    "# plt.ylabel(r'Model residuals')\n",
    "# plt.xlabel(r'$D_{50}$ (mm)')\n",
    "# plt.title(r\"a) \", loc='left')\n",
    "\n",
    "# plt.subplot(222)\n",
    "# plt.stem(df['hs_mean'], df['d50']-ds_est8,  markerfmt='o', linefmt='-', label=r\"f(β, $MSTR$, $T_p$, $H_s$)\")\n",
    "# plt.stem(df['hs_mean'], df['d50']-ds_est4,  markerfmt='p', linefmt='-', label = r\"f(β, $MSTR$, $T_p$)\" )\n",
    "# plt.legend()\n",
    "# plt.ylabel(r'Model residuals')\n",
    "# plt.xlabel(r'$H_s$ (m)')\n",
    "# plt.title(r\"b) \", loc='left')\n",
    "\n",
    "# plt.subplot(223)\n",
    "# plt.stem(df['tp'], df['d50']-ds_est8,  markerfmt='o', linefmt='-', label=r\"f(β, $MSTR$, $T_p$, $H_s$)\")\n",
    "# plt.stem(df['tp'], df['d50']-ds_est4,  markerfmt='p', linefmt='-', label = r\"f(β, $MSTR$, $T_p$)\" )\n",
    "# plt.legend()\n",
    "# plt.ylabel(r'Model residuals')\n",
    "# plt.xlabel(r'$T_p$ (m)')\n",
    "# plt.title(r\"c) \", loc='left')\n",
    "\n",
    "# plt.subplot(224)\n",
    "# plt.stem(df['mstr'], df['d50']-ds_est8,  markerfmt='o', linefmt='-', label=r\"f(β, $MSTR$, $T_p$, $H_s$)\")\n",
    "# plt.stem(df['mstr'], df['d50']-ds_est4,  markerfmt='p', linefmt='-', label = r\"f(β, $MSTR$, $T_p$)\" )\n",
    "# plt.legend()\n",
    "# plt.ylabel(r'Model residuals')\n",
    "# plt.xlabel(r'$MSTR$ (m)')\n",
    "# plt.title(r\"d) \", loc='left')\n",
    "\n",
    "# plt.savefig('../model_plots/ThreeRegions_NI_Mass_EAus_d50-model8_residuals-skill-FINAL.jpg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67b604f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b011f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = df['d50'].mean()\n",
    "\n",
    "\n",
    "fig=plt.figure(figsize=(20,10))\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "####################\n",
    "test_score = np.zeros((model1.n_estimators,), dtype=np.float64)\n",
    "for i, y_pred1 in enumerate(model1.staged_predict(X_test1)):\n",
    "    test_score[i] = model1.loss_(y_test1, y_pred1)\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(r\"a) f(β)\", loc='left')\n",
    "plt.plot(\n",
    "    np.arange(model1.n_estimators) + 1,\n",
    "    100*(np.sqrt(model1.train_score_)/mm),\n",
    "    \"b-\",\n",
    "    label=\"Training set\",\n",
    ")\n",
    "plt.plot(\n",
    "    np.arange(model1.n_estimators) + 1, 100*(np.sqrt(test_score)/mm), \"r--\", label=\"Test set\", lw=2\n",
    ")\n",
    "plt.axhline(20, linestyle=':',label='20% threshold')\n",
    "# plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"Boosting iterations\")\n",
    "plt.ylabel(\"Mean deviance (%)\")\n",
    "plt.ylim(0,75)\n",
    "plt.legend(loc=0)\n",
    "\n",
    "###########################\n",
    "test_score = np.zeros((model2.n_estimators,), dtype=np.float64)\n",
    "for i, y_pred2 in enumerate(model2.staged_predict(X_test2)):\n",
    "    test_score[i] = model2.loss_(y_test2, y_pred2)\n",
    "\n",
    "plt.subplot(2,2, 2)\n",
    "plt.title(r\"b) f($MSTR$)\", loc='left')\n",
    "plt.plot(\n",
    "    np.arange(model2.n_estimators) + 1,\n",
    "    100*(np.sqrt(model2.train_score_)/mm),\n",
    "    \"b-\",\n",
    "    label=\"Training set\",\n",
    ")\n",
    "plt.plot(\n",
    "    np.arange(model2.n_estimators) + 1, 100*(np.sqrt(test_score)/mm), \"r--\", label=\"Test set\", lw=2\n",
    ")\n",
    "plt.axhline(20, linestyle=':',label='20% threshold')\n",
    "# plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"Boosting iterations\")\n",
    "# plt.ylabel(\"Deviance (non-dim.)\")\n",
    "plt.ylim(0,75)\n",
    "\n",
    "#############################\n",
    "test_score = np.zeros((model3.n_estimators,), dtype=np.float64)\n",
    "for i, y_pred3 in enumerate(model3.staged_predict(X_test3)):\n",
    "    test_score[i] = model3.loss_(y_test3, y_pred3)\n",
    "\n",
    "plt.subplot(2,2, 3)\n",
    "plt.title(\"c) f(β, $MSTR$)\", loc='left')\n",
    "plt.plot(\n",
    "    np.arange(model3.n_estimators) + 1,\n",
    "    100*(np.sqrt(model3.train_score_)/mm),\n",
    "    \"b-\",\n",
    "    label=\"Training set\",\n",
    ")\n",
    "plt.plot(\n",
    "    np.arange(model3.n_estimators) + 1, 100*(np.sqrt(test_score)/mm), \"r--\", label=\"Test set\", lw=2\n",
    ")\n",
    "plt.axhline(20, linestyle=':',label='20% threshold')\n",
    "# plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"Boosting iterations\")\n",
    "# plt.ylabel(\"Deviance (non-dim.)\")\n",
    "plt.ylim(0,75)\n",
    "\n",
    "\n",
    "#####################\n",
    "test_score = np.zeros((model5.n_estimators,), dtype=np.float64)\n",
    "for i, y_pred5 in enumerate(model5.staged_predict(X_test5)):\n",
    "    test_score[i] = model5.loss_(y_test5, y_pred5)\n",
    "    \n",
    "plt.subplot(2,2,4)\n",
    "plt.title(r\"d) f(β, $MSTR$, $H_s$) \", loc='left')\n",
    "plt.plot(\n",
    "    np.arange(model5.n_estimators) + 1,\n",
    "    100*(np.sqrt(model5.train_score_)/mm),\n",
    "    \"b-\",\n",
    "    label=\"Training set\",\n",
    ")\n",
    "plt.plot(\n",
    "    np.arange(model5.n_estimators) + 1, 100*(np.sqrt(test_score)/mm), \"r--\", label=\"Test set\", lw=2\n",
    ")\n",
    "plt.axhline(20, linestyle=':',label='20% threshold')\n",
    "# plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"Boosting iterations\")\n",
    "plt.ylabel(\"Mean deviance (%)\")\n",
    "plt.ylim(0,75)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "# plt.savefig('../model_plots/ThreeRegions_NI_Mass_EAus_d50-4models-training-FINAL.jpg', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('../model_plots/ThreeRegions_NI_Mass_EAus_d50-4models-training-FINAL2.jpg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b58fc6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9a2d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig=plt.figure(figsize=(12,8))\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "########################\n",
    "result = permutation_importance(\n",
    "    model1, X_test1, y_test1, n_repeats=10, random_state=42, n_jobs=2\n",
    ")\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "ax=plt.subplot(221)\n",
    "plt.boxplot(\n",
    "    result.importances[sorted_idx].T,\n",
    "    vert=False,\n",
    "    labels=np.array(feature_names1)[sorted_idx],\n",
    ")\n",
    "\n",
    "plt.xlim(0,2)\n",
    "plt.title(\"a) f(β) \", loc='left')\n",
    "plt.xlabel(\"Permutation importance\\n (non-dim.), test set\")\n",
    "plt.ylabel(\"Variable\")\n",
    "plt.setp(ax.get_yticklabels (), rotation=30)\n",
    "\n",
    "#########################\n",
    "result = permutation_importance(\n",
    "    model2, X_test2, y_test2, n_repeats=10, random_state=42, n_jobs=2\n",
    ")\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "ax=plt.subplot(222)\n",
    "plt.boxplot(\n",
    "    result.importances[sorted_idx].T,\n",
    "    vert=False,\n",
    "    labels=np.array(feature_names2)[sorted_idx],\n",
    ")\n",
    "\n",
    "plt.xlim(0,2)\n",
    "plt.title(\"b) f($MSTR$) \", loc='left')\n",
    "# plt.xlabel(\"Permutation importance (non-dim.), test set\")\n",
    "# plt.ylabel(\"Variable\")\n",
    "plt.setp(ax.get_yticklabels (), rotation=30)\n",
    "\n",
    "#############################\n",
    "result = permutation_importance(\n",
    "    model3, X_test3, y_test3, n_repeats=10, random_state=42, n_jobs=2\n",
    ")\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "ax=plt.subplot(223)\n",
    "plt.boxplot(\n",
    "    result.importances[sorted_idx].T,\n",
    "    vert=False,\n",
    "    labels=np.array(feature_names3)[sorted_idx],\n",
    ")\n",
    "\n",
    "plt.xlim(0,2)\n",
    "plt.title(\"c) f(β + $MSTR$) \", loc='left')\n",
    "# plt.xlabel(\"Permutation importance (non-dim.), test set\")\n",
    "# plt.ylabel(\"Variable\")\n",
    "plt.setp(ax.get_yticklabels (), rotation=30)\n",
    "\n",
    "\n",
    "############################\n",
    "result = permutation_importance(\n",
    "    model5, X_test5, y_test5, n_repeats=10, random_state=42, n_jobs=2\n",
    ")\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "ax=plt.subplot(224)\n",
    "plt.boxplot(\n",
    "    result.importances[sorted_idx].T,\n",
    "    vert=False,\n",
    "    labels=np.array(feature_names5)[sorted_idx],\n",
    ")\n",
    "plt.xlim(0,2)\n",
    "plt.title(r\"d) f(β, $MSTR$, $H_s$)\", loc='left')\n",
    "plt.xlabel(\"Permutation importance\\n (non-dim.), test set\")\n",
    "plt.ylabel(\"Variable\")\n",
    "plt.setp(ax.get_yticklabels (), rotation=30)\n",
    "\n",
    "fig.tight_layout()\n",
    "# plt.savefig('../model_plots/ThreeRegions_NI_Mass_EAus_d50-4models-featimps-FINAL.jpg', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('../model_plots/ThreeRegions_NI_Mass_EAus_d50-4models-featimps-FINAL2.jpg', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d096e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1414689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('../model_out/dataset_TwoRegions_NIR_MASS_coast_model1_FINAL.npy', model1out, allow_pickle=True)\n",
    "# np.save('../model_out/dataset_TwoRegions_NIR_MASS_coast_model2_FINAL.npy', model2out, allow_pickle=True)\n",
    "# np.save('../model_out/dataset_TwoRegions_NIR_MASS_coast_model3_FINAL.npy', model3out, allow_pickle=True)\n",
    "# np.save('../model_out/dataset_TwoRegions_NIR_MASS_coast_model5_FINAL.npy', model5out, allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca8f17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../model_out/dataset_ThreeRegions_EAus_NIR_MASS_coast_model1_FINAL.npy', model1out, allow_pickle=True)\n",
    "np.save('../model_out/dataset_ThreeRegions_EAus_NIR_MASS_coast_model2_FINAL.npy', model2out, allow_pickle=True)\n",
    "np.save('../model_out/dataset_ThreeRegions_EAus_NIR_MASS_coast_model3_FINAL.npy', model3out, allow_pickle=True)\n",
    "np.save('../model_out/dataset_ThreeRegions_EAus_NIR_MASS_coast_model5_FINAL.npy', model5out, allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c51fcaaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01, 0.1, 0.075, 0.05, 0.05, 0.1, 0.075, 0.05]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [model1.get_params()['learning_rate'], model2.get_params()['learning_rate'], model3.get_params()['learning_rate'],\n",
    "#  model4.get_params()['learning_rate'], model5.get_params()['learning_rate'], model6.get_params()['learning_rate'],\n",
    "#  model7.get_params()['learning_rate'], model8.get_params()['learning_rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de785d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5, 5, 5, 3, 5, 3, 7]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [model1.get_params()['max_depth'], model2.get_params()['max_depth'], model3.get_params()['max_depth'],\n",
    "#  model4.get_params()['max_depth'], model5.get_params()['max_depth'], model6.get_params()['max_depth'],\n",
    "#  model7.get_params()['max_depth'], model8.get_params()['max_depth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "099a3563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[300, 25, 100, 200, 200, 25, 50, 200]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [model1.get_params()['n_estimators'], model2.get_params()['n_estimators'], model3.get_params()['n_estimators'],\n",
    "#  model4.get_params()['n_estimators'], model5.get_params()['n_estimators'], model6.get_params()['n_estimators'],\n",
    "#  model7.get_params()['n_estimators'], model8.get_params()['n_estimators']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d9078a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 0.75, 1.0, 0.75, 0.75, 1.0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [model1.get_params()['subsample'], model2.get_params()['subsample'], model3.get_params()['subsample'],\n",
    "#  model4.get_params()['subsample'], model5.get_params()['subsample'], model6.get_params()['subsample'],\n",
    "#  model7.get_params()['subsample'], model8.get_params()['subsample']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c37c115e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 9, 7, 5, 5, 5, 7, 7]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [model1.get_params()['min_samples_split'], model2.get_params()['min_samples_split'], model3.get_params()['min_samples_split'],\n",
    "#  model4.get_params()['min_samples_split'], model5.get_params()['min_samples_split'], model6.get_params()['min_samples_split'],\n",
    "#  model7.get_params()['min_samples_split'], model8.get_params()['min_samples_split']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a26b11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['squared_error',\n",
       " 'squared_error',\n",
       " 'absolute_error',\n",
       " 'absolute_error',\n",
       " 'huber',\n",
       " 'huber',\n",
       " 'huber',\n",
       " 'absolute_error']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [model1.get_params()['loss'], model2.get_params()['loss'], model3.get_params()['loss'],\n",
    "#  model4.get_params()['loss'], model5.get_params()['loss'], model6.get_params()['loss'],\n",
    "#  model7.get_params()['loss'], model8.get_params()['loss']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8244e97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d82ace21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testlim = 100\n",
    "# trainlim = 100\n",
    "\n",
    "# fig = plt.figure(figsize=(12,8))\n",
    "# plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "\n",
    "# plt.subplot(2,5,1)\n",
    "# plt.hist(X_train5[:,2], bins=np.arange(0,1,.1))\n",
    "# plt.ylim(0,trainlim); plt.ylabel('Train set'); plt.xlabel(r'$H_s$ (m)')\n",
    "# plt.title(r'a) ', loc='left')\n",
    "\n",
    "# plt.subplot(2,5,2)\n",
    "# plt.hist(X_train4[:,2], bins=np.arange(3,10,.5))\n",
    "# plt.ylim(0,trainlim); plt.xlabel(r'$T_p$ (s)')\n",
    "# plt.title(r'b)', loc='left')\n",
    "\n",
    "# plt.subplot(2,5,3)\n",
    "# plt.hist(X_train6[:,2], bins=np.arange(50,180,10))\n",
    "# plt.ylim(0,trainlim); plt.xlabel(r'$\\theta$ (dir.)')\n",
    "# plt.title(r'c) ', loc='left')\n",
    "\n",
    "# plt.subplot(2,5,4)\n",
    "# plt.hist(X_train4[:,3], bins=np.arange(0.2,2.5,.1))\n",
    "# plt.ylim(0,trainlim); plt.xlabel('T (m)')\n",
    "# plt.title(r'd) ', loc='left')\n",
    "\n",
    "# plt.subplot(2,5,5)\n",
    "# plt.hist(y_train4, bins=np.arange(0,1,.1))\n",
    "# plt.ylim(0,trainlim); plt.xlabel(r'$D_{50}$ (mm)')\n",
    "# plt.title(r'e) ', loc='left')\n",
    "\n",
    "# plt.subplot(2,5,6)\n",
    "# plt.hist(X_test5[:,2], bins=np.arange(0,1,.1))\n",
    "# plt.ylim(0,testlim); plt.ylabel('Test set'); plt.xlabel(r'$H_s$ (m)')\n",
    "# plt.title(r'f) ', loc='left')\n",
    "\n",
    "# plt.subplot(2,5,7)\n",
    "# plt.hist(X_test4[:,2], bins=np.arange(3,10,.5))\n",
    "# plt.ylim(0,testlim); plt.xlabel(r'$T_p$ (s)')\n",
    "# plt.title(r'g)', loc='left')\n",
    "\n",
    "# plt.subplot(2,5,8)\n",
    "# plt.hist(X_test6[:,2], bins=np.arange(50,180,10))\n",
    "# plt.ylim(0,testlim); plt.xlabel(r'$\\theta$ (dir.)')\n",
    "# plt.title(r'h) ', loc='left')\n",
    "\n",
    "# plt.subplot(2,5,9)\n",
    "# plt.hist(X_test4[:,3], bins=np.arange(0.2,2.5,.1))\n",
    "# plt.ylim(0,testlim); plt.xlabel('T (m)')\n",
    "# plt.title(r'i) ', loc='left')\n",
    "\n",
    "# plt.subplot(2,5,10)\n",
    "# plt.hist(y_test4, bins=np.arange(0,1,.1))\n",
    "# plt.ylim(0,testlim); plt.xlabel('$D_{50}$ (mm)')\n",
    "# plt.title(r'j) ', loc='left')\n",
    "\n",
    "# plt.savefig('../data_plots/TwoRegions_NI_Mass_d50-test_train_dists-FINAL.jpg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07425065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f50ba44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
